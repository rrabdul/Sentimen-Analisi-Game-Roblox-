{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1v1tnKQaMndI9xsEdO3QB-Z_NdLhdE3yi","authorship_tag":"ABX9TyMTXY6hpmXj7WnzA18Vfb1z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"7Zet0zdvhVje","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750939256574,"user_tz":-420,"elapsed":17566,"user":{"displayName":"MUHAMMAD ABDUL ROFIQ","userId":"17973665634158899388"}},"outputId":"ec9f8e80-4c01-4e99-ef79-02f99db6e34c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting Sastrawi\n","  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n","Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/209.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Sastrawi\n","Successfully installed Sastrawi-1.0.1\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["!pip install Sastrawi\n","!pip install nltk\n","import pickle\n","from pickle import UnpicklingError\n","import re\n","import string\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n","import requests\n","import json\n","import nltk\n","nltk.download('punkt_tab')\n","nltk.download('punkt')\n","nltk.download('stopwords')"]},{"cell_type":"markdown","source":["# Testing"],"metadata":{"id":"spaRU2mhGPVE"}},{"cell_type":"code","source":["try:\n","    with open('/content/svm_model.pkl', 'rb') as f:\n","        svm = pickle.load(f)\n","except (EOFError, UnpicklingError) as e:\n","    print(f\"Error loading xgb model: {e}\")\n","\n","    print(\"Check if 'svm_model.pkl' exists and is not empty.\")\n","    print(\"If the file was transferred, ensure it was done in binary mode.\")\n","\n","\n","try:\n","    with open('/content/tfidf_vectorizer.pkl', 'rb') as f:\n","        tfidf = pickle.load(f)\n","except (EOFError, UnpicklingError) as e:\n","    print(f\"Error loading TF-IDF vectorizer: {e}\")\n","\n","\n","def cleaningText(text):\n","    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n","    text = re.sub(r'#[A-Za-z0-9]+', '', text)\n","    text = re.sub(r\"http\\S+\", '', text)\n","    text = re.sub(r'[0-9]+', '', text)\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    text = text.replace('\\n', ' ')\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    text = ' '.join([word for word in text.split() if word.lower() not in [\"mobile\", \"bni\", \"wondr\", \"bni mobile\"]])\n","    text = text.strip(' ')\n","    return text\n","\n","def casefoldingText(text):\n","    text = text.lower()\n","    return text\n","\n","def tokenizingText(text):\n","    text = word_tokenize(text)\n","    return text\n","\n","def filteringText(text):\n","    listStopwords = set(stopwords.words('indonesian'))\n","    listStopwords1 = set(stopwords.words('english'))\n","    listStopwords.update(listStopwords1)\n","    listStopwords.update(['iya','yaa','gak','nya','na','sih','ku','di','ya','loh','kah','deh'])\n","    filtered = []\n","    for txt in text:\n","        if txt not in listStopwords:\n","            filtered.append(txt)\n","    text = filtered\n","    return text\n","\n","def stemmingText(text):\n","    factory = StemmerFactory()\n","    stemmer = factory.create_stemmer()\n","    words = text.split()\n","    stemmed_words = [stemmer.stem(word) for word in words]\n","    stemmed_text = ' '.join(stemmed_words)\n","    return stemmed_text\n","\n","def toSentence(list_words):\n","    sentence = ' '.join(word for word in list_words)\n","    return sentence\n","\n","def fix_slangwords(text):\n","    words = text.split()\n","    fixed_words = []\n","    for word in words:\n","        if word.lower() in slangwords:\n","            fixed_words.append(slangwords[word.lower()])\n","        else:\n","            fixed_words.append(word)\n","    fixed_text = ' '.join(fixed_words)\n","    return fixed_text\n","\n","url = 'https://raw.githubusercontent.com/aninanandah/datasetproject/main/slangwords.json'  # URL tempat kamus slangwords disimpan\n","\n","response = requests.get(url)\n","\n","if response.status_code == 200:\n","    try:\n","        slangwords = json.loads(response.text)\n","    except json.JSONDecodeError as e:\n","        print(\"Error decoding JSON:\", e)\n","        print(\"Response content:\", response.text)\n","else:\n","    print(\"Failed to fetch data from URL. Status code:\", response.status_code)\n","\n","def preprocess_text(text):\n","    text = cleaningText(text)\n","    text = casefoldingText(text)\n","    text = fix_slangwords(text)\n","    text = tokenizingText(text)\n","    text = filteringText(text)\n","    text = toSentence(text)\n","    return text\n","\n","def prediksi_sentimen_kalimat_baru(review_baru, tfidf, svm):\n","\n","    review_baru_cleaned = cleaningText(review_baru)\n","    review_baru_casefolded = casefoldingText(review_baru_cleaned)\n","    review_baru_slangfixed = fix_slangwords(review_baru_casefolded)\n","    review_baru_tokenized = tokenizingText(review_baru_slangfixed)\n","    review_baru_filtered = filteringText(review_baru_tokenized)\n","    review_baru_final = toSentence(review_baru_filtered)\n","\n","\n","    X_review_baru = tfidf.transform([review_baru_final])\n","\n","\n","    X_review_baru = X_review_baru.toarray()\n","\n","\n","    prediksi_sentimen = svm.predict(X_review_baru)\n","\n","\n","    if prediksi_sentimen[0] == 'positive':\n","        hasil = \"Sentimen review baru adalah POSITIF.\"\n","    elif prediksi_sentimen[0] == 'negative':\n","        hasil = \"Sentimen review baru adalah NEGATIF.\"\n","    else:\n","        hasil = \"Sentimen review baru adalah NETRAL.\"\n","\n","    return hasil"],"metadata":{"id":"ai7dob2qGQwa","executionInfo":{"status":"ok","timestamp":1750939484648,"user_tz":-420,"elapsed":217,"user":{"displayName":"MUHAMMAD ABDUL ROFIQ","userId":"17973665634158899388"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ibLx33MFGtLr","executionInfo":{"status":"ok","timestamp":1750939511488,"user_tz":-420,"elapsed":18847,"user":{"displayName":"MUHAMMAD ABDUL ROFIQ","userId":"17973665634158899388"}},"outputId":"202cac51-76a3-4c65-bfad-d94f69559192"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["review_baru = \"sering ngelag\"\n","prediksi_sentimen_kalimat_baru(review_baru, tfidf, svm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"PwQN4pu_GXcC","executionInfo":{"status":"ok","timestamp":1750939513614,"user_tz":-420,"elapsed":63,"user":{"displayName":"MUHAMMAD ABDUL ROFIQ","userId":"17973665634158899388"}},"outputId":"ebaf825f-16bc-4346-f1a0-7a479cc36b88"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Sentimen review baru adalah NEGATIF.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["review_baru = \" Sangat membantu, mudah\"\n","prediksi_sentimen_kalimat_baru(review_baru, tfidf, svm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"wjVKO8EtGZmR","executionInfo":{"status":"ok","timestamp":1750939514940,"user_tz":-420,"elapsed":113,"user":{"displayName":"MUHAMMAD ABDUL ROFIQ","userId":"17973665634158899388"}},"outputId":"dabf2e9e-5694-4b5f-ba5f-331d13a77c9c"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Sentimen review baru adalah NEGATIF.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["review_baru = \"sering eror\"\n","prediksi_sentimen_kalimat_baru(review_baru, tfidf, svm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"t_TgLyktGbdp","executionInfo":{"status":"ok","timestamp":1750939538577,"user_tz":-420,"elapsed":73,"user":{"displayName":"MUHAMMAD ABDUL ROFIQ","userId":"17973665634158899388"}},"outputId":"ce1cffb2-2c8a-4cf0-baa6-74d35be6fb26"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Sentimen review baru adalah NEGATIF.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]}]}